{
 "metadata": {
  "name": "",
  "signature": "sha256:b11d0920671e5104cd64ed6e8a91ef4afb56dc41c7f19107a70b693931991a08"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic\n",
      "%load_ext autoreload\n",
      "%matplotlib inline\n",
      "%autoreload 2\n",
      "import numpy as np\n",
      "import gzip, pickle\n",
      "from collections import OrderedDict\n",
      "from word2vec_extended import Word2VecExtended\n",
      "from IPython.display import clear_output\n",
      "import sys\n",
      "sys.path.append(\"/Users/jonathanraiman/Desktop/Coding/language_modeling/\")\n",
      "from yelplm import YelpLM, CategoriesConverter, DatasetGenerator\n",
      "lmsenti = Word2VecExtended.load(\"/Users/jonathanraiman/Desktop/Coding/language_modeling/saves/kid_model_30_oov_senti\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However there is a speedup using Cython (and it is even larger if we do not allocate extra memory, and write directly to the objects we want):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit using_theano()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 941 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit using_cython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 282 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit using_numpy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 859 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Either get the data from mongo:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import connect_to_database, get_some_restaurants\n",
      "connect_to_database(database_name = 'yelp')\n",
      "max_el = 10000\n",
      "texts, texts_data = get_some_restaurants(max_el, min_words = 10) # be as large as a single window.\n",
      "with gzip.open(\"saves/saved_texts.gz\", 'wb') as file:\n",
      "    pickle.dump((texts, texts_data), file, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or load the data from drive:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file = gzip.open(\"saves/saved_texts.gz\", 'r')\n",
      "texts, texts_data = pickle.load(file)\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = set()\n",
      "for el in texts_data:\n",
      "    for c in el[\"categories\"]:\n",
      "        categories.add(c)\n",
      "catconvert = CategoriesConverter(categories)\n",
      "dataset_gen = DatasetGenerator(texts, texts_data, catconvert)\n",
      "\n",
      "# should modify this to do some auto-encoding / self regression.\n",
      "model = YelpLM(\n",
      "    vocabulary = lmsenti,\n",
      "    object_vocabulary_size = len(texts),\n",
      "    window = 10,\n",
      "    bilinear_form = False,\n",
      "    size = 20,\n",
      "    object_size = 20,\n",
      "    output_sigmoid_classes = catconvert.num_categories,\n",
      "    output_classes=[5, 5] # \"\", \"$\", \"$$\",...,\"$$$$\", 5 price classes, and 5 rating classes\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.reset_weights()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging\n",
      "logger = logging.getLogger(\"yelplm.training\")\n",
      "logger.setLevel(logging.INFO - 1)\n",
      "#observation_work = np.zeros(model.window * model.size + model.object_size, dtype = np.float32)\n",
      "#distribution_work = np.zeros(model.output_size, dtype = np.float32)\n",
      "min_alpha = float(0.001)\n",
      "max_alpha = float(0.0035)\n",
      "max_epoch = 9\n",
      "for epoch in range(0, max_epoch):\n",
      "    alpha = max(min_alpha, max_alpha * (1. - (float(epoch) / float(max_epoch))))\n",
      "    model._alpha = alpha\n",
      "    objects, err = model.train(dataset_gen, workers = 8, chunksize = 24)\n",
      "    #for example in dataset_gen:\n",
      "    #    total_error += train_sentence_concatenation(model, np.array([model.vocab.get_index(word) for word in example[0]], dtype=np.int32), example[1], example[2], example[3], alpha, distribution_work, observation_work)\n",
      "    print(\"Error = %.3f, alpha = %.3f\" % (err, alpha))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:yelplm.training:training model with 8 workers\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.create_normalized_matrices()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.most_similar_word(\"stale\", topn = 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "[('almond', 0.9149297475814819, 19214),\n",
        " ('flour', 0.9102924466133118, 5948),\n",
        " ('slices', 0.9019582271575928, 8311),\n",
        " ('section', 0.8974441289901733, 39035),\n",
        " ('opening', 0.8955057263374329, 8595),\n",
        " ('earth', 0.8866500854492188, 15871),\n",
        " ('worst', 0.883548378944397, 21715),\n",
        " ('appetizer', 0.8818886876106262, 16371),\n",
        " ('walked', 0.8814980983734131, 8367),\n",
        " ('present', 0.881054162979126, 34621)]"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import present_restaurant\n",
      "from IPython.display import display, HTML\n",
      "import re\n",
      "\n",
      "def levenshtein_distance(source, target):\n",
      "    if len(source) < len(target):\n",
      "        return levenshtein_distance(target, source)\n",
      " \n",
      "    # So now we have len(source) >= len(target).\n",
      "    if len(target) == 0:\n",
      "        return len(source)\n",
      " \n",
      "    # We call tuple() to force strings to be used as sequences\n",
      "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
      "    source = np.array(tuple(source))\n",
      "    target = np.array(tuple(target))\n",
      " \n",
      "    # We use a dynamic programming algorithm, but with the\n",
      "    # added optimization that we only need the last two rows\n",
      "    # of the matrix.\n",
      "    previous_row = np.arange(target.size + 1)\n",
      "    for s in source:\n",
      "        # Insertion (target grows longer than source):\n",
      "        current_row = previous_row + 1\n",
      " \n",
      "        # Substitution or matching:\n",
      "        # Target and source items are aligned, and either\n",
      "        # are different (cost of 1), or are the same (cost of 0).\n",
      "        current_row[1:] = np.minimum(\n",
      "                current_row[1:],\n",
      "                np.add(previous_row[:-1], target != s))\n",
      " \n",
      "        # Deletion (target grows shorter than source):\n",
      "        current_row[1:] = np.minimum(\n",
      "                current_row[1:],\n",
      "                current_row[0:-1] + 1)\n",
      " \n",
      "        previous_row = current_row\n",
      " \n",
      "    return previous_row[-1]\n",
      "\n",
      "def search_for_object(self, object_index, topn = 10):\n",
      "    present_restaurant(texts_data[object_index], text = texts[object_index])\n",
      "    for result, distance in self.most_similar_object(object_index, topn=topn):\n",
      "        present_restaurant(texts_data[result], text = texts[result])\n",
      "        display(HTML(\"\"\"\n",
      "            <div>\n",
      "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
      "                    <div style='height:20px; width:%dpx;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
      "                        %.0f%%\n",
      "                    </div>\n",
      "                </div>\n",
      "            </div>\n",
      "            \"\"\" % (int(distance * 100), distance * 100)))\n",
      "def search_with_text(self, text, topn = 10, levenshtein = False):\n",
      "    text = text.lower()\n",
      "    min_distance_index = -1\n",
      "    min_distance = float('inf')\n",
      "    min_distance_word = None\n",
      "    \n",
      "    for i, datum in enumerate(texts_data):\n",
      "        if levenshtein:\n",
      "            min_local_distance = float('inf')\n",
      "            if datum[\"_id\"].lower().find(text) != -1:\n",
      "                min_local_distance = 3\n",
      "                if min_local_distance < min_distance:\n",
      "                    min_distance_word = datum[\"_id\"]\n",
      "                    min_distance = min_local_distance\n",
      "                    min_distance_index = i\n",
      "            for scrap in re.split( \"[ -]\", datum[\"_id\"].lower()) + [datum[\"_id\"].lower()] + datum[\"categories\"]:\n",
      "                min_local_distance = min(min_local_distance, levenshtein_distance(text, scrap))\n",
      "                if min_local_distance < min_distance:\n",
      "                    min_distance_word = scrap\n",
      "                    min_distance = min_local_distance\n",
      "                    min_distance_index = i\n",
      "            if min_distance <= 1:\n",
      "                break\n",
      "        else:\n",
      "            if datum[\"_id\"].lower().find(text) != -1 or datum[\"id\"].lower().find(text) != -1:\n",
      "                min_distance = i\n",
      "                break\n",
      "            for cat in datum[\"categories\"]:\n",
      "                if cat.lower().find(text) != -1:\n",
      "                    min_distance = i\n",
      "                    break\n",
      "            \n",
      "    if min_distance_index == -1 or min_distance == len(text) or min_distance == len(min_distance_word):\n",
      "        print(\"Could not be found\")\n",
      "    else:\n",
      "        if min_distance > 0:\n",
      "            display(HTML(\"\"\"\n",
      "            <span style=\"color: #333\">Did you mean </span> <b>%s</b> <span style=\"color: #333\">(%d edit%s)</span> ?\n",
      "            \"\"\" % (min_distance_word, min_distance, \"s\" if min_distance != 1 else \"\")))\n",
      "        return search_for_object(self, min_distance_index, topn=topn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_with_text(model, \"foodtruck\", levenshtein= True, topn=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "            <span style=\"color: #333\">Did you mean </span> <b>foodtrucks</b> <span style=\"color: #333\">(1 edit)</span> ?\n",
        "            "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x109da2d50>"
       ]
      },
      {
       "html": [
        "\n",
        "    <div>\n",
        "        <h2>plum-burgers-seattle</h2>\n",
        "        <span style='color: #ca0814;'>$</span><span style='color: #e4e4e4;'>$$</span><br /> \n",
        "        <span style='color: #feea60;'>\u2605\u2605\u2605\u2605</span><span style='color: #e4e4e4;'>\u2605</span>\n",
        "        <span style='color:#333;font-size:9px'>397 words</span>\n",
        "        <br/>\n",
        "        <span style='color:#777:font-size:9px'>Categories: </span><span style='color:#333;font-size:13px'>burgers, vegan, foodtrucks</span>\n",
        "        <p style='width:450px'>. the kale was raw , dressed with a soy-ginger dressing , and quite tasty , though cut a bit large ( i had to tear several pieces up to</p>\n",
        "    </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x109da2d50>"
       ]
      },
      {
       "html": [
        "\n",
        "    <div>\n",
        "        <h2>Fog\u00f3n Cocina Mexicana</h2>\n",
        "        <span style='color: #ca0814;'>$$</span><span style='color: #e4e4e4;'>$</span><br /> \n",
        "        <span style='color: #feea60;'>\u2605\u2605\u2605\u2605</span><span style='color: #e4e4e4;'>\u2605</span>\n",
        "        <span style='color:#333;font-size:9px'>400 words</span>\n",
        "        <br/>\n",
        "        <span style='color:#777:font-size:9px'>Categories: </span><span style='color:#333;font-size:13px'>mexican</span>\n",
        "        <p style='width:450px'>like about this place . 1st , the service ; you 're greeted before your seated , then you and your guest are given a nice little mini tostada as</p>\n",
        "    </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "            <div>\n",
        "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
        "                    <div style='height:20px; width:96px;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
        "                        97%\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "    <div>\n",
        "        <h2>Cafe Nordstrom</h2>\n",
        "        <span style='color: #ca0814;'></span><span style='color: #e4e4e4;'>$$$</span><br /> \n",
        "        <span style='color: #feea60;'>\u2605\u2605\u2605\u2605\u2605</span><span style='color: #e4e4e4;'></span>\n",
        "        <span style='color:#333;font-size:9px'>142 words</span>\n",
        "        <br/>\n",
        "        <span style='color:#777:font-size:9px'>Categories: </span><span style='color:#333;font-size:13px'>tradamerican</span>\n",
        "        <p style='width:450px'>they have a cafe until my friend sage mentioned it . this cafe is inside the store in downtown seattle on the fourth floor . i was also surprised the</p>\n",
        "    </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "            <div>\n",
        "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
        "                    <div style='height:20px; width:96px;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
        "                        97%\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "    <div>\n",
        "        <h2>Bibimbap</h2>\n",
        "        <span style='color: #ca0814;'>$</span><span style='color: #e4e4e4;'>$$</span><br /> \n",
        "        <span style='color: #feea60;'>\u2605\u2605\u2605</span><span style='color: #e4e4e4;'>\u2605\u2605</span>\n",
        "        <span style='color:#333;font-size:9px'>159 words</span>\n",
        "        <br/>\n",
        "        <span style='color:#777:font-size:9px'>Categories: </span><span style='color:#333;font-size:13px'>korean</span>\n",
        "        <p style='width:450px'>i should have probably gone with the bibimbap after all ; the onigiri was pretty good , granted , but it was a bit strange . they were a bit</p>\n",
        "    </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "            <div>\n",
        "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
        "                    <div style='height:20px; width:96px;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
        "                        97%\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "    <div>\n",
        "        <h2>Portfolio</h2>\n",
        "        <span style='color: #ca0814;'>$$</span><span style='color: #e4e4e4;'>$</span><br /> \n",
        "        <span style='color: #feea60;'>\u2605\u2605\u2605\u2605</span><span style='color: #e4e4e4;'>\u2605</span>\n",
        "        <span style='color:#333;font-size:9px'>475 words</span>\n",
        "        <br/>\n",
        "        <span style='color:#777:font-size:9px'>Categories: </span><span style='color:#333;font-size:13px'>diners</span>\n",
        "        <p style='width:450px'>the food is all prepared by high-level culinary students and is made incredibly well . service was impeccable and the prices are unbeatable . $ 23 for a 3 course</p>\n",
        "    </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "            <div>\n",
        "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
        "                    <div style='height:20px; width:96px;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
        "                        96%\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "    <div>\n",
        "        <h2>the-hideaway-seattle</h2>\n",
        "        <span style='color: #ca0814;'></span><span style='color: #e4e4e4;'>$$$</span><br /> \n",
        "        <span style='color: #feea60;'>\u2605\u2605</span><span style='color: #e4e4e4;'>\u2605\u2605\u2605</span>\n",
        "        <span style='color:#333;font-size:9px'>80 words</span>\n",
        "        <br/>\n",
        "        <span style='color:#777:font-size:9px'>Categories: </span><span style='color:#333;font-size:13px'>newamerican</span>\n",
        "        <p style='width:450px'>deep fried olives with romesco sauce . desserts are also surprisingly good ... i got a mousse tort & chili read more '' seattle , wa it 's in belltown</p>\n",
        "    </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      },
      {
       "html": [
        "\n",
        "            <div>\n",
        "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
        "                    <div style='height:20px; width:96px;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
        "                        96%\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x15da85f50>"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}